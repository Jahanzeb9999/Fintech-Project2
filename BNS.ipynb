##
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62442320-eb0b-4082-afa0-a3cf3cfba1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca88bbd-c725-42fd-b5cc-1b6d2a23d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "`# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9882c-80ab-42f1-a743-0ac9255d0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using data from Apple's stock.\n",
    "# Using data from Apple's stock.\n",
    "df = dr.data.get_data_yahoo('BNS', start='2016-09-27', end='2022-06-10')\n",
    "df.drop(columns=['High', 'Low', 'Volume', 'Open', 'Adj Close'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19360f20-374a-4995-9d69-c74f313392cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df2, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df2) - window):\n",
    "        features = df2.iloc[i : (i + window), feature_col_number]\n",
    "        target = df2.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8b0c1-e43e-4a0d-a822-d46f9b805344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 30\n",
    "\n",
    "# Set the index of the feature and target columns\n",
    "feature_column = 0\n",
    "target_column = 0\n",
    "\n",
    "# Create the features (X) and target (y) data using the window_data() function.\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "\n",
    "# Print a few sample values from X and y\n",
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ee760-79a0-4b3c-9c65-c686a82ec38e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8572c-30e6-485d-85fa-bc600cc23edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the training target data y_train\n",
    "scaler.fit(y_train)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756f4fd-3b56-49d3-9d5d-a4c048cdc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the training target data y_train\n",
    "scaler.fit(y_train)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf13f02-28f3-40dc-949d-3000816f5056",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Reshape the features data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e4e25-f735-4bfe-97a7-403087259096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656244b-5f05-4ffe-a6db-1b6f85ee460a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a2e38-0a2e-4d74-86f6-c7bd1ffb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c7d5d-bc57-449f-90d3-eb2a49b9bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca16d45-e4f0-4120-afa8-23f2cff71ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2196b06-a5df-4801-b9a4-8b8a58df3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73a68b-6385-4d06-a981-97a0cd7825af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525ba37-7770-41dc-800a-57475023aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39b6de-1942-48ea-9412-93592b0a7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.DataFrame({\n",
    "    \"Actual\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices) :]\n",
    ")\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d48de-7ca9-4307-a531-44339272b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
